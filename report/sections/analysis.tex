\section{Critical Analysis}
% Strengths and limitations of your approach
% Learning outcomes: what worked, what didn’t, what you’d do differently
% Value of reproducing vs innovating

Our project aimed to adapt the Decision-based Heterogeneous Graph Attention Network (DHGAT) framework to the problem of fake news detection on the LIAR dataset, introducing a dual-channel architecture that separately processes content and social information. Through this process, several strengths and limitations of our approach became evident, providing valuable insights into the challenges and opportunities in graph-based misinformation detection.

One of the principal strengths of our methodology lies in the explicit separation of content and social relational features. By constructing two distinct graphs and dynamically balancing their contributions through a learned attention mechanism, our model was able to better capture the complementary nature of textual content and contextual metadata. This dual-channel design aligns well with the intuition that fake news detection benefits from integrating both intrinsic article properties and extrinsic propagation cues. Furthermore, by simplifying the structural complexity compared to fully heterogeneous graph models, we reduced implementation overhead and made our architecture more interpretable, which is advantageous for both model analysis and practical deployment.

Nevertheless, several limitations emerged during experimentation. First, despite the conceptual advantage of dual graphs, the final performance gains over standard GAT baselines were modest. This suggests that either the extracted social features were not sufficiently informative, or that the relatively simple graph construction method (based on $k$-nearest neighbors) did not fully exploit relational signals. Moreover, the LIAR dataset itself imposes constraints: its metadata is relatively sparse, and its labels are noisy, which may have limited the effectiveness of sophisticated graph modeling strategies. In future work, a richer dataset with explicit user-post engagement graphs (e.g., Weibo or Twitter datasets) could better showcase the advantages of multi-relational GNNs.

From a learning perspective, implementing and adapting GNN models, particularly DHGAT-like architectures, reinforced the importance of thoughtful graph construction and feature engineering. GNN performance depends not only on model design but heavily on how the graph itself is defined. Additionally, working through message-passing mechanisms, attention layers, and dual-modality aggregation provided valuable practical experience in translating theoretical ideas into working, scalable implementations.

One of the key takeaways from this project is the nuanced value of reproducing versus innovating. While reproducing existing architectures helps solidify understanding and provides a strong baseline, innovation—such as adapting DHGAT to a dual-channel homogeneous setting—enables deeper engagement with the specific challenges posed by real-world datasets. However, innovation must be carefully balanced with empirical validation: novel adaptations should be driven by clear hypotheses about the task and should be evaluated critically against simpler alternatives.

Overall, this project highlighted the promise of graph-based techniques for fake news detection while illustrating the need for continued methodological rigor, careful dataset choice, and critical evaluation when applying advanced architectures to complex social problems.
