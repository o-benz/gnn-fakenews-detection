\section{Model Implementation}

In our approach, we implement a model inspired by the Decision-based Heterogeneous Graph Attention Network (DHGAT) framework, adapting its key principles to a dual-channel setting tailored for the structure of the LIAR dataset. While traditional DHGAT architectures operate on a single heterogeneous graph comprising multiple types of nodes and edges, our model processes two separate homogeneous graphs: a content graph, capturing textual or semantic connections between news articles, and a social graph, representing user interactions or relational context among articles through shared audiences or speaker affiliations.

Each graph is independently processed through a dedicated stack of GATConv layers, where each GATConv layer applies an attention mechanism to weigh neighbor nodes dynamically during message passing. The content channel is configured with a higher representational capacity, utilizing wider hidden dimensions, to better capture the richness and variability of textual information. The social channel, by contrast, focuses on relational structures with a smaller, but still expressive, feature space. Between GATConv layers, we apply non-linear activations (ELU) and dropout regularization to prevent overfitting. Furthermore, batch normalization is applied separately to the outputs of each channel to promote stable and accelerated convergence during training.

Drawing from the decision-making philosophy inherent in DHGAT, we introduce a Dual-Channel Attention mechanism that learns node-specific attention weights to adaptively balance the contributions of content-based and social-based information. Specifically, for each node, the model computes independent attention scores for the content and social embeddings and applies a softmax function to produce a normalized weighting across the two modalities. This mechanism can be interpreted as an analogue to the relation selection process in heterogeneous graphs, where the model must decide which types of edges are most informative; however, in our setting, the decision is made at the modality level, selecting between two distinct sources of information rather than multiple edge types.

After attention-based reweighting, the attended content and social features are concatenated and passed through a multi-layer perceptron (MLP) composed of two fully connected layers with ELU activations, dropout, and residual connections to preserve expressive power. A final linear layer maps the resulting embeddings to the output space, corresponding to the set of possible fake news labels. The model is trained end-to-end using a negative log-likelihood loss derived from the log-softmax outputs, optimizing both the GNN parameters and the attention mechanism jointly.

Through this architectural design, our adapted DHGAT retains the core spirit of decision-based information aggregation while simplifying the structural complexity by leveraging dual homogeneous graphs. This makes it particularly well-suited to the nature of the LIAR dataset, where distinct content and social information streams exist but are not explicitly multi-relational within a single graph structure. Future work could extend this approach by reintroducing full heterogeneous processing, allowing finer-grained relational decisions across multiple edge types for even greater modeling flexibility.